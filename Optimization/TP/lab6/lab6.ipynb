{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Optimization techniques Lab. 6: Bayesian Optmization\n",
        "## Introduction\n",
        "**Goal.** The goal of this lab is to study the behavior of Bayesian optimization on a regression problem and a classifier one. \n",
        "Bayesian optimization is a probabilistic approach that uses the Bayes' Theorem $P(A|B) = \\frac{P(B|A)*P(A)}{P(B)}. Briefly, we use the prior information, P(A),(random samples) to optimize a surrogate function, P(B|A).\n",
        "\n",
        "**Getting started.** The following cells contain the implementation of the methods that we will use throughout this lab, together with utilities. \n",
        "\n",
        "https://machinelearningmastery.com/what-is-bayesian-optimization/\n"
      ],
      "metadata": {
        "id": "eK4fQ2q-Xcx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "id": "R5uQkLcFS1GT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1804a2f1-2637-4c83-9e0d-0db722af05df"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.7.3)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.2.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of bayesian optimization for a 1d function from scratch\n",
        "from math import sin\n",
        "from math import pi\n",
        "from numpy import arange\n",
        "from numpy import vstack\n",
        "from numpy import argmax\n",
        "from numpy import asarray\n",
        "from numpy.random import normal\n",
        "from numpy.random import random\n",
        "from scipy.stats import norm\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor, GaussianProcessClassifier\n",
        "from warnings import catch_warnings\n",
        "from warnings import simplefilter\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from numpy import mean\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from skopt.space import Integer\n",
        "from skopt.utils import use_named_args\n",
        "from warnings import catch_warnings\n",
        "from skopt import gp_minimize\n",
        "from warnings import simplefilter"
      ],
      "metadata": {
        "id": "kttrGnJOBvhe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hyHpT2yLjqsu"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# surrogate or approximation for the objective function\n",
        "def surrogate(model, X):\n",
        "\t# catch any warning generated when making a prediction\n",
        "\twith catch_warnings():\n",
        "\t\t# ignore generated warnings\n",
        "\t\tsimplefilter(\"ignore\")\n",
        "\t\treturn model.predict(X, return_std=True)\n",
        "\n",
        "def acquisition(X, Xsamples, model):\n",
        "\t# calculate the best surrogate score found so far\n",
        "\tyhat, _ = surrogate(model, X)\n",
        "\tbest = max(yhat)\n",
        "\t# calculate mean and stdev via surrogate function\n",
        "\tmu, std = surrogate(model, Xsamples)\n",
        "\tmu = mu[:, 0]\n",
        "\t# calculate the probability of improvement\n",
        "\tprobs = acquisition_function(mu, best, std)\n",
        "\treturn probs\n",
        "\n",
        "# optimize the acquisition function\n",
        "def opt_acquisition(X, y, model):\n",
        "\t# random search, generate random samples\n",
        "\tXsamples = random(100)\n",
        "\tXsamples = Xsamples.reshape(len(Xsamples), 1)\n",
        "\t# calculate the acquisition function for each sample\n",
        "\tscores = acquisition(X, Xsamples, model)\n",
        "\t# locate the index of the largest scores\n",
        "\tix = argmax(scores)\n",
        "\treturn Xsamples[ix, 0]\n",
        "\n",
        "# plot real observations vs surrogate function\n",
        "def plot(X, y, model):\n",
        "\t# scatter plot of inputs and real objective function\n",
        "\tpyplot.scatter(X, y)\n",
        "\t# line plot of surrogate function across domain\n",
        "\tXsamples = asarray(arange(0, 1, 0.001))\n",
        "\tXsamples = Xsamples.reshape(len(Xsamples), 1)\n",
        "\tysamples, _ = surrogate(model, Xsamples)\n",
        "\tpyplot.plot(Xsamples, ysamples)\n",
        "\t# show the plot\n",
        "\tpyplot.show()\n",
        "\n",
        "\n",
        "def bayesianOptmization(generation):\n",
        "    # sample the domain sparsely with noise\n",
        "    X , y  = initial_point(size = 200)\n",
        "    # reshape into rows and cols\n",
        "    X = X.reshape(len(X), 1)\n",
        "    y = y.reshape(len(y), 1)\n",
        "    # define the model\n",
        "    model = GaussianProcessRegressor() #you can set the kernel and the optmizer \n",
        "    # fit the model\n",
        "    model.fit(X, y)\n",
        "    # perform the optimization process\n",
        "    for i in range(generation):\n",
        "        # select the next point to sample\n",
        "        x = opt_acquisition(X, y, model)\n",
        "        # sample the point\n",
        "        actual = objective(x)\n",
        "        # summarize the finding\n",
        "        est, _ = surrogate(model, [[x]])\n",
        "        # add the data to the dataset\n",
        "        X = vstack((X, [[x]]))\n",
        "        y = vstack((y, [[actual]]))\n",
        "        # update the model\n",
        "        model.fit(X, y)\n",
        "    return X, y, model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementative part.\n",
        "Your first step, will be to implement the following functions:\n",
        "\n",
        "\n",
        "1.   objective() is the function to optimize. \n",
        "2.   initial_point() returns the initial set of points (a priori knowledge)\n",
        "3.   acquisition_function() implements the acquisition function\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_HsCKJjDVMYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# objective function\n",
        "def objective(x, noise=0.1):\n",
        "\treturn x + normal(loc=0, scale=noise)\n",
        "\n",
        "#remember to return the value in the right order and type.\n",
        "def initial_point(size = 200):\n",
        "    X = random(size)\n",
        "    Y = asarray([objective(x) for x in X])\n",
        "    return X, Y\n",
        "\n",
        "#you have to add the parameters that you need.\n",
        "def acquisition_function(mu, best, std):\n",
        "    return norm.cdf((mu - best) / (std+1E-9))"
      ],
      "metadata": {
        "id": "0QIefWBRTLCH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression\n",
        "---\n",
        "## Questions:\n",
        "- How does the prior knowledge change the optimization?\n",
        "  - With more initial point, we'll have more point next to the optimum, so the result will be more precise\n",
        "- How does the kernel change the optimization? (see here the [kernels](https://scikit-learn.org/stable/modules/gaussian_process.html#kernels-for-gaussian-processes))\n",
        "- ow does the acquisition function affect the optimization?"
      ],
      "metadata": {
        "id": "B8swyFr8AYZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, model = bayesianOptmization(1)\n",
        "plot(X, y, model)\n",
        "# best result\n",
        "ix = argmax(y)\n",
        "print('Best Result: x=%.3f, y=%.3f' % (X[ix], y[ix]))"
      ],
      "metadata": {
        "id": "KNEsNnVYuzE0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "84259b31-6a5f-4686-f980-ca3cd36578e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Result: x=0.968, y=1.174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifier\n",
        "---\n",
        "## Questions:\n",
        "- Try different ranges of hyperparameters. How do the results change?\n",
        "  - With more neighbours, the accuracy at the end is better, and I don't know what the second parameters influence.\n",
        "  When the 2 scales are too close, the accuracy is at 1, otherwise I can be lower \n",
        "- Does the model influence the choice of the hyperparameters?\n",
        "\n"
      ],
      "metadata": {
        "id": "dzw4lTn9A5MK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate 2d classification dataset\n",
        "X, y = make_blobs(n_samples=500, centers=3, n_features=2)\n",
        "# define the model\n",
        "\n",
        "model = KNeighborsClassifier()\n",
        "# define the space of hyperparameters to search\n",
        "search_space = [Integer(1, 10, name='n_neighbors'), Integer(5, 6, name='p')]\n",
        "\n",
        "# define the function used to evaluate a given configuration\n",
        "@use_named_args(search_space)\n",
        "def evaluate_model(**params):\n",
        "    # something\n",
        "    model.set_params(**params)\n",
        "    # calculate 5-fold cross validation\n",
        "    with catch_warnings():\n",
        "        # ignore generated warnings\n",
        "        simplefilter(\"ignore\")\n",
        "        result = cross_val_score(model, X, y, cv=5, n_jobs=-1, scoring='accuracy')\n",
        "        # calculate the mean of the scores\n",
        "        estimate = mean(result)\n",
        "        return 1.0 - estimate\n",
        "        \n",
        "\n",
        "\n",
        "# perform optimization\n",
        "result = gp_minimize(evaluate_model, search_space)\n",
        "# summarizing finding:\n",
        "print('Best Accuracy: %.3f' % (1.0 - result.fun))\n",
        "print('Best Parameters: n_neighbors=%d, p=%d' % (result.x[0], result.x[1]))"
      ],
      "metadata": {
        "id": "jQBZkkzBvR3Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67729c7d-5965-4a53-d566-9dfbd83cba36"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-35d94e006912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# perform optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;31m# summarizing finding:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best Accuracy: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    257\u001b[0m             noise=noise)\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     return base_minimize(\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macq_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py\u001b[0m in \u001b[0;36mtell\u001b[0;34m(self, x, y, fit)\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_tell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py\u001b[0m in \u001b[0;36m_tell\u001b[0;34m(self, x, y, fit)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_xs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcand_acq_func\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcand_acq_funcs_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m                 values = _gaussian_acquisition(\n\u001b[0m\u001b[1;32m    558\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m                     \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcand_acq_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/skopt/acquisition.py\u001b[0m in \u001b[0;36m_gaussian_acquisition\u001b[0;34m(X, model, y_opt, acq_func, return_grad, acq_func_kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0macq_func\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"EI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"EIps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PIps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0macq_func\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"EI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"EIps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mfunc_and_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_ei\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mfunc_and_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_pi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/skopt/acquisition.py\u001b[0m in \u001b[0;36mgaussian_ei\u001b[0;34m(X, model, y_opt, xi, return_grad)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# check dimensionality of mu, std so we can divide them below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/skopt/learning/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, return_std, return_cov, return_mean_grad, return_std_grad)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;31m# Compute variance of predictive distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 \u001b[0my_var\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ki,kj,ij->k\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_inv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0;31m# Check if any of the variances is negative because of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/einsumfunc.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspecified_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mc_einsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m     \u001b[0;31m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BONUS\n",
        "\n",
        "You see in the classifier the effect of hyperparameter tuning. \n",
        "You can now change the acquisition functions in the regression problem, adding a slack variable as a hyperparameter. How does this variable affect the optimization problem?"
      ],
      "metadata": {
        "id": "EvVHVIoCqLWX"
      }
    }
  ]
}